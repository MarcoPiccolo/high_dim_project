{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ee3224-5897-4903-b465-21d9a77071bc",
   "metadata": {},
   "source": [
    "Preprocessing of the arrest dataset: copy the json file in this folder, change its parameters and execute this script to save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point # used to find the corresponding spatial zone\n",
    "import json\n",
    "import sys\n",
    "import os # to use functions defined in other scripts\n",
    "\n",
    "# add scripts dir to path\n",
    "# Add the relative path to the system path\n",
    "# Load configuration from JSON file \n",
    "with open('arrests_nta_2010_2020_pars.json', 'r') as f: \n",
    "    config = json.load(f) # Add directories to the system path \n",
    "    for folder in config['folders'].values():\n",
    "        abs_path = os.path.abspath(folder)\n",
    "        if abs_path not in sys.path:\n",
    "            sys.path.append(abs_path)\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open('arrests_nta_2010_2020_pars.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Add directories to the system path\n",
    "for folder in config['folders'].values():\n",
    "    abs_path = os.path.abspath(folder)\n",
    "    if abs_path not in sys.path:\n",
    "        sys.path.append(abs_path)\n",
    "\n",
    "# Import the editing scripts\n",
    "from edit_funcs import *\n",
    "\n",
    "# Absolute paths of files\n",
    "core_df_path = os.path.join(os.path.abspath(config['folders']['core_folder_arrests']), config['files']['core_df_path'])\n",
    "var_v1_to_keep_path = os.path.join(os.path.abspath(config['folders']['var_to_keep_folder']), config['files']['var_v1_to_keep_path'])\n",
    "var_v2_to_keep_path = os.path.join(os.path.abspath(config['folders']['var_to_keep_folder']), config['files']['var_v2_to_keep_path'])\n",
    "coordinates_file_path = os.path.join(os.path.abspath(config['folders']['coordinates_maps_folder']), config['files']['coordinates_file_path'])\n",
    "output_df_path = os.path.join(os.path.abspath(config['folders']['final_datasets_folder']), config['files']['output_df_path'])\n",
    "census_data_path = os.path.join(os.path.abspath(config['folders']['census_folder']), config['files']['census_data_path'])\n",
    "census_var_to_keep_path = os.path.join(os.path.abspath(config['folders']['census_var_to_keep_folder']), config['files']['census_var_to_keep_path'])\n",
    "\n",
    "# Other useful variables\n",
    "date_variable_name = config['variables']['date_variable_name']\n",
    "age_group_variable_name = config['variables']['age_group_variable_name']\n",
    "considered_years_list = config['variables']['considered_years_list']\n",
    "census_coord_var_name = config['variables']['census_coord_var_name']\n",
    "census_coord_value_to_keep = config['variables']['census_coord_value_to_keep']\n",
    "df_space_var_name = config['variables']['df_space_var_name']\n",
    "census_df_space_var_name = config['variables']['census_df_space_var_name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851fe42",
   "metadata": {},
   "source": [
    "Filter columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5e0a71-72af-4a6d-83b3-8679986c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load first df of variables to keep\n",
    "\n",
    "var_v1_to_keep_df = pd.read_csv(var_v1_to_keep_path)\n",
    "\n",
    "df = FilterColumns(df = pd.read_csv(core_df_path),\n",
    "                   var_df = var_v1_to_keep_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013dbb6",
   "metadata": {},
   "source": [
    "Filter rows: keep only years selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29cdae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FilterRowsContains(df = df,\n",
    "                        var_name = date_variable_name,\n",
    "                        accepted_var_values = considered_years_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d825a",
   "metadata": {},
   "source": [
    "Add MONTH variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de21eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = AddMONTH(df = df,\n",
    "    date_var_name= date_variable_name,\n",
    "    date_format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7caa21",
   "metadata": {},
   "source": [
    "Add YEAR variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a7a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = AddYEAR(df = df,\n",
    "    date_var_name= date_variable_name,\n",
    "    date_format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627a147",
   "metadata": {},
   "source": [
    "Add NTA indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5273708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the GeoJSON file into a GeoDataFrame\n",
    "gdf = gpd.read_file(coordinates_file_path)\n",
    "\n",
    "df = ConvertToGeodf(df,\n",
    "                    long = \"Longitude\",\n",
    "                    lat = \"Latitude\",\n",
    "                    crs = gdf.crs)\n",
    "# actually join the two by inclusion:\n",
    "# df coordinates which are in polygons defined by gdf data\n",
    "df = SJoinWithinGeo(geodf_units = df,\n",
    "                    geodf2_polygons = gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78d058",
   "metadata": {},
   "source": [
    "Second column filtering.\n",
    "Remove latitude and longitude coordinates variables.\n",
    "Remove complete date time variable.\n",
    "(WARNING: we're using a different columns to keep file: arrests_v2).\n",
    "Here we keep both Census tract variable (CTLabel) both NTA variable (NTA2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ef20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first df of variables to keep\n",
    "var_v2_to_keep_df = pd.read_csv(var_v2_to_keep_path)\n",
    "\n",
    "# filter columns\n",
    "df = FilterColumns(df = df, var_df = var_v2_to_keep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcc97d",
   "metadata": {},
   "source": [
    "Look for missing and most likely values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed671b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'ARREST_DATE': ARREST_DATE\n",
      "2010-01-20    1773\n",
      "2012-03-07    1750\n",
      "2012-02-01    1726\n",
      "2010-05-20    1725\n",
      "2010-03-05    1700\n",
      "              ... \n",
      "2020-03-29     152\n",
      "2020-06-21     151\n",
      "2012-10-29     150\n",
      "2014-12-25     136\n",
      "2010-12-27      91\n",
      "Name: count, Length: 4018, dtype: int64\n",
      "Unique values in column 'KY_CD': KY_CD\n",
      "235.0    497406\n",
      "344.0    381255\n",
      "343.0    237115\n",
      "341.0    193962\n",
      "348.0    178706\n",
      "          ...  \n",
      "349.0        50\n",
      "455.0        25\n",
      "123.0         9\n",
      "577.0         5\n",
      "357.0         4\n",
      "Name: count, Length: 73, dtype: int64\n",
      "Unique values in column 'LAW_CAT_CD': LAW_CAT_CD\n",
      "M    2344897\n",
      "F     985323\n",
      "V     195291\n",
      "I      15573\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'AGE_GROUP': AGE_GROUP\n",
      "25-44    1665397\n",
      "18-24     917388\n",
      "45-64     679711\n",
      "<18       259459\n",
      "65+        33404\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_SEX': PERP_SEX\n",
      "M    2948940\n",
      "F     606419\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_RACE': PERP_RACE\n",
      "BLACK                             1719415\n",
      "WHITE HISPANIC                     908297\n",
      "WHITE                              430243\n",
      "BLACK HISPANIC                     296182\n",
      "ASIAN / PACIFIC ISLANDER           156867\n",
      "UNKNOWN                             36087\n",
      "AMERICAN INDIAN/ALASKAN NATIVE       8268\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'NTA2020': NTA2020\n",
      "MN1102    87305\n",
      "MN0501    64517\n",
      "MN0502    63717\n",
      "BK1602    62885\n",
      "BX0101    61541\n",
      "          ...  \n",
      "SI9593       34\n",
      "SI9561       25\n",
      "BK1061       23\n",
      "QN8492       22\n",
      "QN1371       22\n",
      "Name: count, Length: 252, dtype: int64\n",
      "Unique values in column 'MONTH': MONTH\n",
      "3     324945\n",
      "5     319354\n",
      "1     313095\n",
      "4     308805\n",
      "8     304306\n",
      "10    303275\n",
      "7     297826\n",
      "2     294917\n",
      "6     293093\n",
      "9     283398\n",
      "11    266926\n",
      "12    245419\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Unique values in column '{column}': { df[column].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a51fa0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec8b097",
   "metadata": {},
   "source": [
    "First we uniform missing values to UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8009c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['(null)'], 'UNKNOWN', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a08988",
   "metadata": {},
   "source": [
    "Second we remove non understandable age group values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecffe51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14536\\3774651995.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[age_group_variable_name].replace([\"2020\", \"2019\", \"-977\", \"-962\", \"-71\", \"-12\", \"-942\", \"1020\", \"-965\", \"1925\", \"-928\",\n"
     ]
    }
   ],
   "source": [
    "df[age_group_variable_name].replace([\"2020\", \"2019\", \"-977\", \"-962\", \"-71\", \"-12\", \"-942\", \"1020\", \"-965\", \"1925\", \"-928\",\n",
    "            \"-948\", \"-967\", \"-4\", \"-958\", \"943\", \"-968\", \"949\", \"-973\", \"-2\", \"932\", \"-31\", \"-938\",\n",
    "            \"1016\", \"1014\", \"-60\", \"-1\", \"938\", \"950\", \"-963\"],\n",
    "           'UNKNOWN',\n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cffe8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'ARREST_DATE': ARREST_DATE\n",
      "2010-01-20    1773\n",
      "2012-03-07    1750\n",
      "2012-02-01    1726\n",
      "2010-05-20    1725\n",
      "2010-03-05    1700\n",
      "              ... \n",
      "2020-03-29     152\n",
      "2020-06-21     151\n",
      "2012-10-29     150\n",
      "2014-12-25     136\n",
      "2010-12-27      91\n",
      "Name: count, Length: 4018, dtype: int64\n",
      "Unique values in column 'KY_CD': KY_CD\n",
      "235.0    497406\n",
      "344.0    381255\n",
      "343.0    237115\n",
      "341.0    193962\n",
      "348.0    178706\n",
      "          ...  \n",
      "349.0        50\n",
      "455.0        25\n",
      "123.0         9\n",
      "577.0         5\n",
      "357.0         4\n",
      "Name: count, Length: 73, dtype: int64\n",
      "Unique values in column 'LAW_CAT_CD': LAW_CAT_CD\n",
      "M    2344897\n",
      "F     985323\n",
      "V     195291\n",
      "I      15573\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'AGE_GROUP': AGE_GROUP\n",
      "25-44    1665397\n",
      "18-24     917388\n",
      "45-64     679711\n",
      "<18       259459\n",
      "65+        33404\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_SEX': PERP_SEX\n",
      "M    2948940\n",
      "F     606419\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_RACE': PERP_RACE\n",
      "BLACK                             1719415\n",
      "WHITE HISPANIC                     908297\n",
      "WHITE                              430243\n",
      "BLACK HISPANIC                     296182\n",
      "ASIAN / PACIFIC ISLANDER           156867\n",
      "UNKNOWN                             36087\n",
      "AMERICAN INDIAN/ALASKAN NATIVE       8268\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'NTA2020': NTA2020\n",
      "MN1102    87305\n",
      "MN0501    64517\n",
      "MN0502    63717\n",
      "BK1602    62885\n",
      "BX0101    61541\n",
      "          ...  \n",
      "SI9593       34\n",
      "SI9561       25\n",
      "BK1061       23\n",
      "QN8492       22\n",
      "QN1371       22\n",
      "Name: count, Length: 252, dtype: int64\n",
      "Unique values in column 'MONTH': MONTH\n",
      "3     324945\n",
      "5     319354\n",
      "1     313095\n",
      "4     308805\n",
      "8     304306\n",
      "10    303275\n",
      "7     297826\n",
      "2     294917\n",
      "6     293093\n",
      "9     283398\n",
      "11    266926\n",
      "12    245419\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Unique values in column '{column}': { df[column].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df7265",
   "metadata": {},
   "source": [
    "Join with selected census dataset by space location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083dc776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    BK1601\n",
      "1    BX0101\n",
      "2    MN1101\n",
      "3    MN1002\n",
      "4    BX1102\n",
      "Name: NTA2020, dtype: object\n",
      "0    BK0101\n",
      "1    BK0101\n",
      "2    BK0101\n",
      "3    BK0101\n",
      "4    BK0101\n",
      "Name: NTA2020, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read census data\n",
    "census_df = pd.read_csv(census_data_path, \n",
    "                        sep = \",\")\n",
    "\n",
    "# keep all\n",
    "# filter type of coordinates\n",
    "# census_df = FilterRowsContains(df = census_df,\n",
    "                               # var_name = census_coord_var_name,\n",
    "                               # accepted_var_values = census_coord_value_to_keep)\n",
    "\n",
    "# read census variables to keep\n",
    "# census_var_to_keep_df = pd.read_csv(census_var_to_keep_path,\n",
    "                                    # sep = \";\")\n",
    "\n",
    "# filter columns\n",
    "\n",
    "# census_df = FilterColumns(df = census_df,\n",
    "                          # var_df = census_var_to_keep_df)\n",
    "\n",
    "# Ensure key columns have the same data type \n",
    "df[df_space_var_name] = df[df_space_var_name].astype(str)\n",
    "census_df[census_df_space_var_name] = census_df[census_df_space_var_name].astype(str)\n",
    "\n",
    "# debug\n",
    "print(df[df_space_var_name].head())\n",
    "print(census_df[census_df_space_var_name].head())\n",
    "\n",
    "# join with df based on GeoID\n",
    "df = pd.merge(df, census_df,\n",
    "              left_on = df_space_var_name,\n",
    "              right_on = census_df_space_var_name,\n",
    "              how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5288e",
   "metadata": {},
   "source": [
    "Save to csv a different file for each year, due to computational issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c5a6aea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m years_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2010\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2011\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2012\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2013\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2014\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2015\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2016\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2017\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2019\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2020\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years_list:\n\u001b[1;32m----> 7\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mFilterRowsContains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYEAR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43maccepted_var_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43myear\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     temp_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../final_datasets/arrests_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nta.CSV\u001b[39m\u001b[38;5;124m\"\u001b[39m ,index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Progetti\\NYC\\data\\edit_scripts_and_params\\edit_funcs.py:40\u001b[0m, in \u001b[0;36mFilterRowsContains\u001b[1;34m(df, var_name, accepted_var_values)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFilterRowsContains\u001b[39m(df, var_name, accepted_var_values):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Filter pandas dataframe rows by keeping only the rows for which\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    the var_name column contains at least one the accepted values.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Example accepted_var_values = [\"ab\", \"bc\", \"cd\"]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        - pd.dataframe of filtered pandas dataframe with only the rows satisfying the condition\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccepted_var_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m])\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Progetti\\NYC\\data\\edit_scripts_and_params\\edit_funcs.py:40\u001b[0m, in \u001b[0;36mFilterRowsContains.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFilterRowsContains\u001b[39m(df, var_name, accepted_var_values):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Filter pandas dataframe rows by keeping only the rows for which\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    the var_name column contains at least one the accepted values.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Example accepted_var_values = [\"ab\", \"bc\", \"cd\"]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        - pd.dataframe of filtered pandas dataframe with only the rows satisfying the condition\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(df[df[var_name]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccepted_var_values\u001b[49m\u001b[43m)\u001b[49m)])\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Progetti\\NYC\\data\\edit_scripts_and_params\\edit_funcs.py:40\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFilterRowsContains\u001b[39m(df, var_name, accepted_var_values):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Filter pandas dataframe rows by keeping only the rows for which\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    the var_name column contains at least one the accepted values.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Example accepted_var_values = [\"ab\", \"bc\", \"cd\"]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        - pd.dataframe of filtered pandas dataframe with only the rows satisfying the condition\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(df[df[var_name]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28many\u001b[39m(\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m accepted_var_values))])\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "# save the entire dataset to one unique file\n",
    "# df.to_csv(output_df_path, index = False)\n",
    "\n",
    "years_list = [2010, \"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]\n",
    "\n",
    "for year in years_list:\n",
    "    temp_df = FilterRowsContains(df = df,\n",
    "                        var_name = \"YEAR\",\n",
    "                        accepted_var_values = [year])\n",
    "    temp_df.to_csv(f\"../../../final_datasets/arrests_{year}_nta.CSV\" ,index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
