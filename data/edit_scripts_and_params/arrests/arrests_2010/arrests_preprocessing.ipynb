{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ee3224-5897-4903-b465-21d9a77071bc",
   "metadata": {},
   "source": [
    "Preprocessing of the arrest dataset: copy the json file in this folder, change its parameters and execute this script to save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea44b028",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arrests_nta_2010_2020_pars.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;66;03m# to use functions defined in other scripts\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# add scripts dir to path\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Add the relative path to the system path\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load configuration from JSON file \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marrests_nta_2010_2020_pars.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f: \n\u001b[0;32m     12\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f) \u001b[38;5;66;03m# Add directories to the system path \u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfolders\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arrests_nta_2010_2020_pars.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point # used to find the corresponding spatial zone\n",
    "import json\n",
    "import sys\n",
    "import os # to use functions defined in other scripts\n",
    "\n",
    "# add scripts dir to path\n",
    "# Add the relative path to the system path\n",
    "# Load configuration from JSON file \n",
    "with open('arrests_nta_2010_2020_pars.json', 'r') as f: \n",
    "    config = json.load(f) # Add directories to the system path \n",
    "    for folder in config['folders'].values():\n",
    "        abs_path = os.path.abspath(folder)\n",
    "        if abs_path not in sys.path:\n",
    "            sys.path.append(abs_path)\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Load configuration from JSON file\n",
    "with open('arrests_nta_2010_2020_pars.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Add directories to the system path\n",
    "for folder in config['folders'].values():\n",
    "    abs_path = os.path.abspath(folder)\n",
    "    if abs_path not in sys.path:\n",
    "        sys.path.append(abs_path)\n",
    "\n",
    "# Import the editing scripts\n",
    "from edit_funcs import *\n",
    "\n",
    "# Absolute paths of files\n",
    "core_df_path = os.path.join(os.path.abspath(config['folders']['core_folder_arrests']), config['files']['core_df_path'])\n",
    "var_v1_to_keep_path = os.path.join(os.path.abspath(config['folders']['var_to_keep_folder']), config['files']['var_v1_to_keep_path'])\n",
    "var_v2_to_keep_path = os.path.join(os.path.abspath(config['folders']['var_to_keep_folder']), config['files']['var_v2_to_keep_path'])\n",
    "coordinates_file_path = os.path.join(os.path.abspath(config['folders']['coordinates_maps_folder']), config['files']['coordinates_file_path'])\n",
    "output_df_path = os.path.join(os.path.abspath(config['folders']['core_folder_arrests']), config['files']['output_df_path'])\n",
    "census_data_path = os.path.join(os.path.abspath(config['folders']['census_folder']), config['files']['census_data_path'])\n",
    "census_var_to_keep_path = os.path.join(os.path.abspath(config['folders']['census_var_to_keep_folder']), config['files']['census_var_to_keep_path'])\n",
    "\n",
    "# Other useful variables\n",
    "date_variable_name = config['variables']['date_variable_name']\n",
    "age_group_variable_name = config['variables']['age_group_variable_name']\n",
    "considered_years_list = config['variables']['considered_years_list']\n",
    "census_coord_var_name = config['variables']['census_coord_var_name']\n",
    "census_coord_value_to_keep = config['variables']['census_coord_value_to_keep']\n",
    "df_space_var_name = config['variables']['df_space_var_name']\n",
    "census_df_space_var_name = config['variables']['census_df_space_var_name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851fe42",
   "metadata": {},
   "source": [
    "Filter columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5e0a71-72af-4a6d-83b3-8679986c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load first df of variables to keep\n",
    "\n",
    "var_v1_to_keep_df = pd.read_csv(var_v1_to_keep_path)\n",
    "\n",
    "df = FilterColumns(df = pd.read_csv(core_df_path),\n",
    "                   var_df = var_v1_to_keep_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013dbb6",
   "metadata": {},
   "source": [
    "Filter rows: keep only years selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29cdae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FilterRowsContains(df = df,\n",
    "                        var_name = date_variable_name,\n",
    "                        accepted_var_values = considered_years_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d825a",
   "metadata": {},
   "source": [
    "Add MONTH variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de21eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = AddMONTH(df = df,\n",
    "    date_var_name= date_variable_name,\n",
    "    date_format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7caa21",
   "metadata": {},
   "source": [
    "Add YEAR variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = AddYEAR(df = df,\n",
    "    date_var_name= date_variable_name,\n",
    "    date_format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627a147",
   "metadata": {},
   "source": [
    "Add NTA indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5273708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the GeoJSON file into a GeoDataFrame\n",
    "gdf = gpd.read_file(coordinates_file_path)\n",
    "\n",
    "df = ConvertToGeodf(df,\n",
    "                    long = \"Longitude\",\n",
    "                    lat = \"Latitude\",\n",
    "                    crs = gdf.crs)\n",
    "# actually join the two by inclusion:\n",
    "# df coordinates which are in polygons defined by gdf data\n",
    "df = SJoinWithinGeo(geodf_units = df,\n",
    "                    geodf2_polygons = gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78d058",
   "metadata": {},
   "source": [
    "Second column filtering.\n",
    "Remove latitude and longitude coordinates variables.\n",
    "Remove complete date time variable.\n",
    "(WARNING: we're using a different columns to keep file: arrests_v2).\n",
    "Here we keep both Census tract variable (CTLabel) both NTA variable (NTA2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94ef20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first df of variables to keep\n",
    "var_v2_to_keep_df = pd.read_csv(var_v2_to_keep_path)\n",
    "\n",
    "# filter columns\n",
    "df = FilterColumns(df = df, var_df = var_v2_to_keep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcc97d",
   "metadata": {},
   "source": [
    "Look for missing and most likely values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed671b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'ARREST_DATE': ARREST_DATE\n",
      "2010-01-20    1773\n",
      "2010-05-20    1725\n",
      "2010-03-05    1700\n",
      "2010-01-22    1694\n",
      "2010-03-03    1661\n",
      "              ... \n",
      "2010-12-24     356\n",
      "2010-11-25     280\n",
      "2010-12-26     224\n",
      "2010-12-25     171\n",
      "2010-12-27      91\n",
      "Name: count, Length: 365, dtype: int64\n",
      "Unique values in column 'KY_CD': KY_CD\n",
      "235.0    82064\n",
      "344.0    36842\n",
      "343.0    26019\n",
      "677.0    24634\n",
      "117.0    22939\n",
      "         ...  \n",
      "102.0        7\n",
      "349.0        5\n",
      "882.0        4\n",
      "577.0        2\n",
      "357.0        1\n",
      "Name: count, Length: 69, dtype: int64\n",
      "Unique values in column 'LAW_CAT_CD': LAW_CAT_CD\n",
      "M    292227\n",
      "F     97524\n",
      "V     29548\n",
      "I      1890\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'AGE_GROUP': AGE_GROUP\n",
      "25-44    183083\n",
      "18-24    118629\n",
      "45-64     75032\n",
      "<18       42577\n",
      "65+        3001\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_SEX': PERP_SEX\n",
      "M    352850\n",
      "F     69472\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_RACE': PERP_RACE\n",
      "BLACK                             208789\n",
      "WHITE HISPANIC                    110216\n",
      "WHITE                              49981\n",
      "BLACK HISPANIC                     32889\n",
      "ASIAN / PACIFIC ISLANDER           15141\n",
      "UNKNOWN                             4406\n",
      "AMERICAN INDIAN/ALASKAN NATIVE       900\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'NTA2020': NTA2020\n",
      "MN1102    10624\n",
      "MN0501     8345\n",
      "BK1602     8103\n",
      "MN0502     8010\n",
      "BK0302     7570\n",
      "          ...  \n",
      "SI9593        3\n",
      "SI9592        2\n",
      "QN1371        2\n",
      "QN8492        2\n",
      "BK1892        1\n",
      "Name: count, Length: 251, dtype: int64\n",
      "Unique values in column 'MONTH': MONTH\n",
      "3     37818\n",
      "4     37795\n",
      "10    37728\n",
      "5     37447\n",
      "1     37437\n",
      "6     36040\n",
      "8     35391\n",
      "7     35176\n",
      "9     34143\n",
      "11    33327\n",
      "2     31714\n",
      "12    28306\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Unique values in column '{column}': { df[column].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a51fa0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec8b097",
   "metadata": {},
   "source": [
    "First we uniform missing values to UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8009c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['(null)'], 'UNKNOWN', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a08988",
   "metadata": {},
   "source": [
    "Second we remove non understandable age group values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecffe51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12444\\3774651995.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[age_group_variable_name].replace([\"2020\", \"2019\", \"-977\", \"-962\", \"-71\", \"-12\", \"-942\", \"1020\", \"-965\", \"1925\", \"-928\",\n"
     ]
    }
   ],
   "source": [
    "df[age_group_variable_name].replace([\"2020\", \"2019\", \"-977\", \"-962\", \"-71\", \"-12\", \"-942\", \"1020\", \"-965\", \"1925\", \"-928\",\n",
    "            \"-948\", \"-967\", \"-4\", \"-958\", \"943\", \"-968\", \"949\", \"-973\", \"-2\", \"932\", \"-31\", \"-938\",\n",
    "            \"1016\", \"1014\", \"-60\", \"-1\", \"938\", \"950\", \"-963\"],\n",
    "           'UNKNOWN',\n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffe8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'ARREST_DATE': ARREST_DATE\n",
      "2010-01-20    1773\n",
      "2010-05-20    1725\n",
      "2010-03-05    1700\n",
      "2010-01-22    1694\n",
      "2010-03-03    1661\n",
      "              ... \n",
      "2010-12-24     356\n",
      "2010-11-25     280\n",
      "2010-12-26     224\n",
      "2010-12-25     171\n",
      "2010-12-27      91\n",
      "Name: count, Length: 365, dtype: int64\n",
      "Unique values in column 'KY_CD': KY_CD\n",
      "235.0    82064\n",
      "344.0    36842\n",
      "343.0    26019\n",
      "677.0    24634\n",
      "117.0    22939\n",
      "         ...  \n",
      "102.0        7\n",
      "349.0        5\n",
      "882.0        4\n",
      "577.0        2\n",
      "357.0        1\n",
      "Name: count, Length: 69, dtype: int64\n",
      "Unique values in column 'LAW_CAT_CD': LAW_CAT_CD\n",
      "M    292227\n",
      "F     97524\n",
      "V     29548\n",
      "I      1890\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'AGE_GROUP': AGE_GROUP\n",
      "25-44    183083\n",
      "18-24    118629\n",
      "45-64     75032\n",
      "<18       42577\n",
      "65+        3001\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_SEX': PERP_SEX\n",
      "M    352850\n",
      "F     69472\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'PERP_RACE': PERP_RACE\n",
      "BLACK                             208789\n",
      "WHITE HISPANIC                    110216\n",
      "WHITE                              49981\n",
      "BLACK HISPANIC                     32889\n",
      "ASIAN / PACIFIC ISLANDER           15141\n",
      "UNKNOWN                             4406\n",
      "AMERICAN INDIAN/ALASKAN NATIVE       900\n",
      "Name: count, dtype: int64\n",
      "Unique values in column 'NTA2020': NTA2020\n",
      "MN1102    10624\n",
      "MN0501     8345\n",
      "BK1602     8103\n",
      "MN0502     8010\n",
      "BK0302     7570\n",
      "          ...  \n",
      "SI9593        3\n",
      "SI9592        2\n",
      "QN1371        2\n",
      "QN8492        2\n",
      "BK1892        1\n",
      "Name: count, Length: 251, dtype: int64\n",
      "Unique values in column 'MONTH': MONTH\n",
      "3     37818\n",
      "4     37795\n",
      "10    37728\n",
      "5     37447\n",
      "1     37437\n",
      "6     36040\n",
      "8     35391\n",
      "7     35176\n",
      "9     34143\n",
      "11    33327\n",
      "2     31714\n",
      "12    28306\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Unique values in column '{column}': { df[column].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df7265",
   "metadata": {},
   "source": [
    "Join with selected census dataset by space location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083dc776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12444\\1780135901.py:2: DtypeWarning: Columns (3,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  census_df = pd.read_csv(census_data_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471     BX0803\n",
      "478     BK0802\n",
      "545     MN0502\n",
      "1452    BK0202\n",
      "1453    BX0102\n",
      "Name: NTA2020, dtype: object\n",
      "128    BK0101\n",
      "129    BK0102\n",
      "130    BK0103\n",
      "131    BK0104\n",
      "132    BK0201\n",
      "Name: GeoID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read census data\n",
    "census_df = pd.read_csv(census_data_path, \n",
    "                        sep = \",\")\n",
    "\n",
    "# keep all\n",
    "# filter type of coordinates\n",
    "census_df = FilterRowsContains(df = census_df,\n",
    "                               var_name = census_coord_var_name,\n",
    "                               accepted_var_values = census_coord_value_to_keep)\n",
    "\n",
    "# read census variables to keep\n",
    "census_var_to_keep_df = pd.read_csv(census_var_to_keep_path,\n",
    "                                    sep = \";\")\n",
    "\n",
    "# filter columns\n",
    "\n",
    "census_df = FilterColumns(df = census_df,\n",
    "                          var_df = census_var_to_keep_df)\n",
    "\n",
    "# Ensure key columns have the same data type \n",
    "df[df_space_var_name] = df[df_space_var_name].astype(str)\n",
    "census_df[census_df_space_var_name] = census_df[census_df_space_var_name].astype(str)\n",
    "\n",
    "# debug\n",
    "print(df[df_space_var_name].head())\n",
    "print(census_df[census_df_space_var_name].head())\n",
    "\n",
    "# join with df based on GeoID\n",
    "df = pd.merge(df, census_df,\n",
    "              left_on = df_space_var_name,\n",
    "              right_on = census_df_space_var_name,\n",
    "              how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5288e",
   "metadata": {},
   "source": [
    "Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c5a6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(output_df_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
