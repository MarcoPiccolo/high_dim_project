---
title: "Arrests 2010 NTA: Analisi"
output: pdf_document
---

# Analisi NTA 2010 - 2011 interazione tra variabili

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.align = 'center')
```

```{r, message=FALSE, warning=FALSE, results='hide'}
rm(list = ls())
gc(verbose = FALSE)
library(gridExtra)

# plotting parameters 1d plot
OUT.WIDTH.1d = "100%"
OUT.HEIGHT.1d = "100%"

# plotting parameters 2d plots
OUT.WIDTH = "60%"
OUT.HEIGHT = "70%"

source("functions_script.R")
```

```{r}
# Condition: if TRUE execute the computational heavy chuncks, else not
# assuming the models are been loaded from a RData file before.
# IMPORTANT: in order to reproduce the result set bool_execute_heavy_chunks = TRUE

bool_execute_heavy_chunks = FALSE
file_save_name = "rdata/arrests_nta_2010_models_summary.Rdata"
load(file_save_name)

file_joined_zero_counts_2010_df = "rdata/joined_zero_counts_2010.Rdata"
load(file_joined_zero_counts_2010_df)

month.yesint.cv.k4.sets.name = "rdata/month_cv_set_name.RData"
month.zeros.cv.k4.sets.name = "rdata/month_zeros_cv_set_name.RData"



# best models fitted on all data
# estimated_best_models = TRUE
# models_fitted_file_name = "models_fitted_nta_2010.Rdata"
# 
# # require loading models_summary list
# if(!estimated_best_models){
#   load(models_fitted_file_name)
# } else{
#   # store each model useful information:
#   # validation error and beta for best lambda
#   models_fitted_file_name = list()
# }
```


```{r}
# Preprocessing -------------------------------------
# read the data
df_2010 = read.csv("../../data/final_datasets/arrests_2010_nta.csv", stringsAsFactors = T)

# test set
df_2011 = read.csv("../../data/final_datasets/arrests_2011_nta.csv", stringsAsFactors = T)
```

```{r, message=FALSE, results='hide'}
df_2010$ARREST_DATE = NULL
df_2010$YEAR = NULL
df_2010$Latitude = NULL
df_2010$Longitude = NULL

df_2010$NTA2020 = factor(df_2010$NTA2020)
df_2010$MONTH = factor(df_2010$MONTH)

# add NA category
df_2010$KY_CD = ifelse(is.na(df_2010$KY_CD), "MISSING", df_2010$KY_CD)
df_2010$KY_CD = factor(df_2010$KY_CD)

str(df_2010)

# check for NA
apply(df_2010, 2, function(col) (sum(is.na(col))))

# the ratio is high
nrow(na.omit(df_2010)) / nrow(df_2010)

# delete missing values
df_2010 = na.omit(df_2010)


df_2011$ARREST_DATE = NULL
df_2011$YEAR = NULL
df_2011$Latitude = NULL
df_2011$Longitude = NULL

df_2011$NTA2020 = factor(df_2011$NTA2020)
df_2011$MONTH = NULL

# add NA category
df_2011$KY_CD = ifelse(is.na(df_2011$KY_CD), "MISSING", df_2011$KY_CD)
df_2011$KY_CD = factor(df_2011$KY_CD)

str(df_2011)

# check for NA
apply(df_2011, 2, function(col) (sum(is.na(col))))

# the ratio is high
nrow(na.omit(df_2011)) / nrow(df_2011)

# delete missing values
df_2011 = na.omit(df_2011)
```


## Descrizione

L'obbiettivo di questa sezione di analisi è verificare se esiste un sottoinsieme di variabili esplicative particolarmente correlate con il numero di arresti, sia marginalmente che considerando l'interazione con ciascuna zona spaziale (NTA).
Per vincoli computazionali si riduce l'insieme di stima al solo anno 2010: per quest'anno i dati del censo sono esatti e non si sono verificati eventi rari a differenza del 2020 (Covid); l'insieme di verifica scelto è l'anno 2011, in quanto è l'anno più vicino al 2010 (l'assunzione è che i due anni siano abbastanza simili per il fenomeno considerato).

### Problematiche

Questi dati presentano diverse problematiche.

Le scelte fatte sono dovute a fattori computazionali, di tempo e al fatto che per permettere conteggi diversi da 1 è necessario considerare zone spaziali e intervalli temporali non eccessivamente ristretti.

Per selezione delle variabili di stratificazione per zona da includere, benchè il censo fornisca molte variabili si è scelto di considerarne solo un esiguo sottoinsieme: ciò è dovuto a una mancanza di conoscenza di campo e al non poter dedicare eccessivo tempo alla selezione ed in particolare all'estrazione delle stesse dai varia database e fogli di calcolo.

Per quanto concerne gli intervalli temporali si è scelto di ignorare i possibili trend e considerare i singoli anni, per ciascun anno si sono utilizzati i mesi per la costruzione degli insiemi di convalida incrociata. Pur avendo a disposizione il giorno di ciascun arresto la selezione dei mesi è apparsa come un giusto compromesso per garantire dei conteggi superiori a 1.

Pur avendo notevolmente ridotto la potenziale complessità del problema il numero di osservazioni e il numero di modalità dei fattori alcune procedure impiegate possono comunque molto tempo (sulle piattaforme di calcolo impiegate) per essere eseguite: questi limiti rendono proibitive valutazioni dell'incertezza nelle stime, quali metodi bootstrap o bayesiani.

Poichè i conteggi sono costruiti raggruppando le osservazioni con le stesse combinazioni di modalità delle covariate, il conteggio minimo osservabile è uguale a 1.
Ciò pone dei possibili problemi nella stima di modelli che comprendono lo zero nel supporto (ad esempio il modello di Poisson). Si è comunque provato ad adattare modelli (sia a risposta continua che discreta) su questa tipologia di dati.
in linea teorica si dovrebbe aggiungere un'osservazione con conteggio nullo per ogni combinazione di variabili per cui non si verificano casi, la criticità qui è computazionale dovuta all'incremento notevole delle osservazioni; una possibile soluzione è estrarre casualmente un ridotto sottoinsieme di osservazioni con conteggio nullo.


```{r, eval = bool_execute_heavy_chunks, results='hide'}
library(hash)

set.seed(123)

# Save NTA stratification info
nta_strat_df <- df_2010 %>% 
  dplyr::select(-c(KY_CD, AGE_GROUP, PERP_RACE, PERP_SEX, LAW_CAT_CD, MONTH)) %>% 
  unique()

df_2010_no_strat <- df_2010 %>% 
  dplyr::select(-c(Pop1, MdAge, MaleP, Hsp1P, BNHP, OthNHP, WNHP, ANHP, MIncome))

# Number of zero count observations added to each month multiplied by the number of months
Z <- 5 * 10^3

# Initialize the zero counts data frame
zero_counts_2010_df <- as.data.frame(matrix(NA, nrow = Z * 12, ncol = ncol(df_2010_no_strat)))
colnames(zero_counts_2010_df) <- colnames(df_2010_no_strat)

# Get unique values for each column
unique_vals <- apply(df_2010_no_strat, 2, unique)

# Create a hash set to store existing combinations
existing_combinations <- hash()

# Add existing combinations to the hash set
for (i in 1:nrow(df_2010_no_strat)) {
  key <- paste(df_2010_no_strat[i, ], collapse = "_")
  existing_combinations[[key]] <- TRUE
}

# Generate zero counts for each month
for (month in 1:12) {
  for (i in 1:Z) {
    cond <- TRUE
    
    while (cond) {
      proposal <- sapply(unique_vals, function(el) sample(el, 1))
      proposal["MONTH"] <- factor(month, levels = 1:12)
      key <- paste(proposal, collapse = "_")
      
      if (!has.key(key, existing_combinations)) {
        zero_counts_2010_df[(month - 1) * Z + i, ] <- proposal
        existing_combinations[[key]] <- TRUE
        cond <- FALSE
      }
    }
  }
}

# Join with NTA stratification info
joined_zero_counts_2010_df <- left_join(zero_counts_2010_df, nta_strat_df, by = "NTA2020")


# Clean up
rm(df_2010_no_strat)
rm(zero_counts_2010_df)
gc()

# Add count column
joined_zero_counts_2010_df$count <- 0

joined_zero_counts_2010_df = joined_zero_counts_2010_df %>% mutate(across(where(is.character), as.factor))


save(joined_zero_counts_2010_df, file = file_joined_zero_counts_2010_df)

```



```{r, results='hide'}
year_grouped = suppressMessages(df_2010 %>%
  dplyr::select(-"MONTH") %>% 
  group_by_all() %>% 
  summarise(count = n()))

```



A sinistra i conteggi di arresti raggruppati per valori di covariate e a destra il logaritmo della medesima quantità
```{r, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d}
par(mfrow = c(1,2))

year_grouped$count %>%
  table %>% 
  plot(main = "Arrests ratio grouped by covariates",
       xlab = "number of arrests",
       ylab = "absolute frequency")

year_grouped$count %>% 
  log %>% 
  table %>% 
  plot(main = " log arrests count grouped by covariates",
       xlab = "log(arrests count)",
       ylab = "absolute frequency")

par(mfrow = c(1,1))
```



```{r}
# to include zeros
# cols_to_complete = colnames(df_2010)
# cols_to_complete = setdiff(cols_to_complete, "MONTH")
# 
# # Create a data frame with all combinations of the columns
# all_combinations <- expand_grid(!!!syms(cols_to_complete))
# 
# # Summarize the data and complete with zeros
# year_grouped_zeros <- df_2010 %>%
#   select(-MONTH) %>%
#   group_by(across(all_of(cols_to_complete))) %>%
#   summarise(count = n(), .groups = 'drop') %>%
#   ungroup() %>%
#   right_join(all_combinations, by = cols_to_complete) %>%
#   replace_na(list(count = 0))
# 
# print(year_grouped_zeros)

```

### Elevata dimensionalità

I dati presentano elevata dimensionalità considerando le interazioni tra la variabile spaziale (NTA) e le covariate (qualitative) di arrests.
E' comunque interessante provare i metodi di selezione delle variabili anche sui dati senza interazioni.

Per avere delle misure quantitative si considera il dataset in cui si sono definiti i conteggi senza considerare i mesi: si riporta il rapporto tra il numero di osservazioni (righe) e il prodotto tra il numero di modalità di NTA e la somma delle modalità delle variabili qualitative di arrests.

```{r}
var_unique_len = apply(year_grouped,
                       2,
                       function(col) length(unique(col)))
```

Senza considerare KY_CD (esplicativa non spaziale di arrest con più modalità) il rapporto è:
```{r, include = TRUE}
nrow(year_grouped) / (var_unique_len["NTA2020"] *
  sum(var_unique_len[c("LAW_CAT_CD", "AGE_GROUP", "PERP_SEX", "PERP_RACE")]))
```

Considerando anche KY_CD il rapporto è:
```{r, include=TRUE}
nrow(year_grouped) / (var_unique_len["NTA2020"] *
  sum(var_unique_len[c("KY_CD", "LAW_CAT_CD", "AGE_GROUP",
                       "PERP_SEX", "PERP_RACE")]))
```



```{r}

# Poichè dopo alcune prove le procedure si sono rivelate troppo onerose includendo KY_CD si è deciso di # rimuoverla confidando che l'informazione fornita da LAW_CAT_CD sia comunuque informativa.
# df_2010$KY_CD = NULL
# df_2011$KY_CD = NULL
```

## Modelli

### Criterio di selezione dei parametri di regolazione

Come già accennato, i parametri di regolazione sono selezionati tramite convalida incrociata (CV) impiegando i mesi per la costruzione degli insiemi.

La procedura per la costruzione degli insiemi è la seguente:
- Selezione di k: il numero di insiemi di convalida (ad esempio k = 4)
- Ogni insieme di convalida è composto da osservazioni raggruppate di 12 / k (3) mesi e i mesi rimanenti (9) vengono utilizzati per adattare il modello.
- Per cercare di compensare e mediare le fluttuazioni stagionali, i mesi di validazione sono scelti il più distanziati possibile. Ad esempio, nel caso di k = 4, il primo insieme di validazione è (gennaio, maggio, settembre), il secondo set è (febbraio, giugno, ottobre), il terzo è (marzo, luglio, novembre) e il quarto è (aprile, agosto, dicembre).
- Per rendere ogni risposta comparabile avendo utilizzato un numero diverso di mesi, una nuova risposta è definita come il rapporto degli arresti diviso per il numero di mesi utilizzati nel raggruppamento (ovvero l'esponenziale dell 'offset nel modello di Poisson).


```{r}
# months indexes sets
# each list contains a matrix where each row contains the used indexes
month_sets_ind = list(k4 = matrix(c(1, 5, 9,
                                    2, 6, 10,
                                    3, 7, 11,
                                    4, 8, 12),
                                  byrow = T,
                                  nrow = 4),
                      
                      k6 = matrix(c(1, 7,
                                    2, 8,
                                    3, 9,
                                    4, 10,
                                    5, 11,
                                    6, 12),
                                  byrow = T,
                                  nrow = 6))
```

### Matrice del modello

La matrice del modello considerata è quella con tutte le variabili e le interazioni tra tutte le variabili di arrests tranne KY_CD e le zone spaziali degli NTA
```{r, include=TRUE}


FORMULA.YES.INTERACTIONS = as.formula("count ~. -1 +
                            NTA2020:LAW_CAT_CD + 
                            NTA2020:AGE_GROUP + 
                            NTA2020:PERP_SEX + 
                            NTA2020:PERP_RACE")

# if count is the response variable and and count = 0
# the sparse matrix deletes the row...

FORMULA.YES.INTERACTIONS.sparse = as.formula("temp_response ~. -1 - count +
                            NTA2020:LAW_CAT_CD + 
                            NTA2020:AGE_GROUP + 
                            NTA2020:PERP_SEX + 
                            NTA2020:PERP_RACE")
```


```{r, warning=FALSE, results='hide'}

df_2010_grouped = suppressMessages(df_2010 %>%
  dplyr::select(-MONTH) %>% 
  group_by_all() %>% 
  summarise(count = n()))

df_2011_grouped = suppressMessages(df_2011 %>%
  group_by_all() %>% 
  summarise(count = n()))

df_2010_grouped.matrix = sparse.model.matrix(FORMULA.YES.INTERACTIONS,
                                                df_2010_grouped)

df_2011_grouped.matrix = sparse.model.matrix(FORMULA.YES.INTERACTIONS,
                                                df_2011_grouped)
gc()
```


Poichè la matrice del modello dell'insieme di verifica e quella dell'insieme di stima non condividono tutte le colonne si sceglie di ridurre le colonne di entrambe con l'intersezione  delle colonne in comune.
```{r}


# check dimensions
dim(df_2010_grouped.matrix)
dim(df_2011_grouped.matrix)

col_names_2010 = colnames(df_2010_grouped.matrix)
col_names_2011 = colnames(df_2011_grouped.matrix)

common_col_names = intersect(col_names_2010, col_names_2011)

# in order to use 2011 as a test set we need to uniform the 2011 columns to 2010 colums:
# some bias is introduced here, let's hope it's about small counts
df_2010_grouped.matrix = df_2010_grouped.matrix[,common_col_names]
df_2011_grouped.matrix = df_2011_grouped.matrix[,common_col_names]
```

```{r, eval = bool_execute_heavy_chunks}
# make cv folds

# NO interaction
# month.noint.cv.k4.sets = suppressMessages(MakeMonthCvSets(my_df = df_2010,
#                        month_sets_ind = month_sets_ind$k4,
#                        formula = FORMULA.NO.INTERACTIONS))
# 
month.yesint.cv.k4.sets = suppressMessages(MakeMonthCvSets(my_df = df_2010,
                       month_sets_ind = month_sets_ind$k4,
                       formula = FORMULA.YES.INTERACTIONS))




save(month.yesint.cv.k4.sets, file = month.yesint.cv.k4.sets.name)
```


```{r, eval = bool_execute_heavy_chunks}
# make cv folds adding the zero counts

month.zeros.cv.k4.sets = suppressMessages(MakeMonthCvSetsZeros(my_df = df_2010,
                                              zeros_df = joined_zero_counts_2010_df,
                                              month_sets_ind = month_sets_ind$k4,
                       formula = FORMULA.YES.INTERACTIONS.sparse))

save(month.zeros.cv.k4.sets, file = month.zeros.cv.k4.sets.name)
```


### Esplicative quantitative

Benchè le eslplicative quantitative permettano la specificazione di diverse forme funzionali qui, per ragioni computazionali ci si limita ad assumere (forzatamente) una relazione monotona lineare con la risposta.

### Modelli per risposta continua

Nell'impiego dei modelli con risposta continua (con errori gaussiani i.i.d) si è scelto di stimare il modello su una trasformazione logaritmica della risposta: "y = count / n_month_train" e calcolare l'errore di previsioni sulla trasformazione "count = exp(y) * n_month_test" rispetto al numero di conteggi osservati, in questo modo la previsione è sempre positiva.

### Modelli e procedure considerati

I modelli considerati sono modelli normali con penalizzazioni LASSO, Elasticnet, SCAD ed MCP e modelli Poisson con penalizzazioni LASSO ed Elasticnet. Per per tutti i modelli si seleziona il parametro (eventualmente vettoriale) di regolazione che minimizza l'errore di convalida. Per i metodi per cui il parametro di regolarizzazione ha dimensione 2 si definisce una griglia di valori (di cui si riporta il grafico delle curve di livello dell'errore).
Per i metodi SCAD e MCP, poichè "ncvreg" presenta dei problemi computazionali dovute alle dimensioni del dataset è impiegata la libreria "picasso" che però non fornisce indicazioni rispetto alle regioni non convesse.


```{r, eval = bool_execute_heavy_chunks}
models_summary$lasso <- Lasso_CV(month.yesint.cv.k4.sets,
                                        my.lambda.vals = exp(seq(-20, 2, 0.1)) %>% sort(decreasing = T))
```


```{r, warning = FALSE, eval = bool_execute_heavy_chunks}
models_summary$scad = NonConvex_Cv(cv.sets = month.yesint.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-15, 1, 0.2)) %>% sort(decreasing = TRUE),
                                             my.gamma.vals = seq(2+1e-05, 10, length = 10),
                                         my.penalty = "scad")

# backup to save key model info
save(models_summary, file = file_save_name)

```


```{r, warning = FALSE, eval = bool_execute_heavy_chunks}
models_summary$mcp = NonConvex_Cv(cv.sets = month.yesint.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-15, 1, 0.2)) %>% sort(decreasing = TRUE),
                                             my.gamma.vals = seq(1+1e-05, 10, length = 10),
                                         my.penalty = "mcp")

# backup to save key model info
save(models_summary, file = file_save_name)
```

```{r, eval = bool_execute_heavy_chunks}

models_summary$elasticnet = Elastic_Cv(cv.sets = month.yesint.cv.k4.sets,
                                             my.lambda.vals = exp(seq(-20, 2, 0.3)) %>% sort(decreasing = TRUE),
                                             my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 10))

# backup to save key model info
save(models_summary, file = file_save_name)
```



```{r}
# Known convergence difficult, see help here. https://cran.r-project.org/web/packages/glmnet/vignettes/glmnetFamily.pdf
glmnet.control(mxitnr = 50) # increase maximum no. of IRLS iterations allowed
```


```{r, eval = bool_execute_heavy_chunks, warning=FALSE}
models_summary$lasso.poi = Lasso_Offset_CV(cv.sets = month.yesint.cv.k4.sets,
                                          my.lambda.vals = exp(seq(-15, 3, 0.1)) %>% sort(decreasing = TRUE),
                                          my.family = poisson())

# backup to save key model info
save(models_summary, file = file_save_name)
```

```{r, eval = bool_execute_heavy_chunks, warning=FALSE}
models_summary$lasso.zeros.noint = Lasso_Offset_CV(cv.sets = month.zeros.cv.k4.sets,
                                          my.lambda.vals = exp(seq(-15, 3, 0.1)) %>% sort(decreasing = TRUE),
                                          my.family = poisson())

# backup to save key model info
save(models_summary, file = file_save_name)
```


```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
models_summary$elasticnet.poi = Elastic_Offset_Cv(cv.sets = month.yesint.cv.k4.sets,
                                                        my.lambda.vals = exp(seq(-10, 2, 0.2)) %>% sort(decreasing = TRUE),
                                                        my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 10),
                                                        my.family = poisson())

save(models_summary, file = file_save_name)
```



```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```


```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
models_summary$elasticnet.poi.zeros = Elastic_Offset_Cv(cv.sets = month.zeros.cv.k4.sets,
                                                        my.lambda.vals = exp(seq(-10, 2, 0.2)) %>% sort(decreasing = TRUE),
                                                        my.alpha.vals = seq(1e-5, 1 - 1e-5, length = 20),
                                                        my.family = poisson())
```


```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```

Sia per il modello normale che per quello Poisson il $\lambda$ minimo è molto vicino a zero (poichè la soluzione è sul bordo si dovrebbe provare a diminuire ulteriormente $\lambda$, ma già così i coefficienti sono quasi uguali alle stime non penalizzate).
```{r, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d}
par(mfrow = c(1,2))

PlotOneDim(x = log(models_summary$lasso$lambda),
           y = models_summary$lasso$cv.err.matr$cv.err,
           se = models_summary$lasso$cv.err.matr$cv.se,
           x.min = log(models_summary$lasso$lmin),
           x.1se = log(models_summary$lasso$l1se),
           xlab = "log lambda",
           ylab = "CV error",
           main = "LASSO  CV error",
          min.leg = "lambda min",
           onese.leg = "lambda 1se")

PlotOneDim(x = log(models_summary$lasso.poi$lambda),
           y = models_summary$lasso.poi$cv.err.matr$cv.err,
           se = models_summary$lasso.poi$cv.err.matr$cv.se,
           x.min = log(models_summary$lasso.poi$lmin),
           x.1se = log(models_summary$lasso.poi$l1se),
           xlab = "log lambda",
           ylab = "CV error",
           main = "LASSO Poisson  CV error",
          min.leg = "lambda min",
           onese.leg = "lambda 1se")
```


Elasticnet individua in entrambi i casi un $\alpha$ prossimo a zero (ridge, possibilmente data la forte correlazione tra covariate nella costruzione della matrice del modello), nel modello normale presenta una soluzione molto vicina alle stime non penalizzate ($\lambda$ è prossimo a zero), mentre nel modello Poisson il $\lambda$ selezionato è 

```{r}
models_summary$elasticnet.poi$lmin
```



```{r, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT}
par(mfrow = c(1,2))

TwoParErrPlot(model_list = models_summary$elasticnet,
              row_par_name = "lambda",
              col_par_name = "alpha",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "amin",
              my.main = "Elasticnet  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "alpha")

TwoParErrPlot(model_list = models_summary$elasticnet.poi,
              row_par_name = "lambda",
              col_par_name = "alpha",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "amin",
              my.main = "Elasticnet Poisson  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "alpha")

par(mfrow = c(1,1))
```



```{r, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT}

par(mfrow = c(1,2))

TwoParErrPlot(model_list = models_summary$mcp,
              row_par_name = "lambda",
              col_par_name = "gamma",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "gmin",
              my.main = "MCP  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "gamma")

TwoParErrPlot(model_list = models_summary$scad,
              row_par_name = "lambda",
              col_par_name = "gamma",
              cv_err_matr_name = "cv.err.matr",
              row_par_min_name = "lmin",
              col_par_min_name = "gmin",
              my.main = "SCAD  Cv error contour",
              my.xlab = "log lambda",
              my.ylab = "gamma")

par(mfrow = c(1,1))
```





```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```




```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
### Neg bin Lasso

# Using a hierarchical specification we assume $Y_i \sim P(\mu_i \lambda_i)$ and $\lambda_i \sim Ga(\tau, \tau)$ so marginally the $Y_i$ are negative binomials with variance $\mu_i(1 + \tau \mu_i)$.
# In the R parameterization adopted $\theta = 1/\tau$ which becomes another tuning parameter.

# models_summary$lasso.negbin.noint = LASSO_NegBin_Offset_Cv(cv.sets = month.noint.cv.k4.sets,
#                                                         my.lambda.vals = exp(seq(-3, 5, 0.2)) %>% sort(decreasing = TRUE),
#                                                         my.theta.vals = seq(1e-5, 3, length = 20))
```

```{r, warning=FALSE, eval = bool_execute_heavy_chunks}
# models_summary$lasso.negbin = LASSO_NegBin_Offset_Cv(cv.sets = month.yesint.cv.k4.sets,
#                                                         my.lambda.vals = exp(seq(-10, 2, 0.2)) %>% sort(decreasing = TRUE),
#                                                         my.theta.vals = seq(1e-5, 20, length = 20))
```

```{r, fig.show='hold', out.width = OUT.WIDTH, out.height= OUT.HEIGHT}
par(mfrow = c(1,1))
# 
# TwoParErrPlot(model_list = models_summary$lasso.negbin.noint,
#               row_par_name = "lambda",
#               col_par_name = "theta",
#               cv_err_matr_name = "cv.err.matr",
#               row_par_min_name = "lmin",
#               col_par_min_name = "tmin",
#               my.main = "LASSO Negative Binomial no interaction Cv error contour",
#               my.xlab = "log lambda",
#               my.ylab = "theta")

# TwoParErrPlot(model_list = models_summary$lasso.negbin,
#               row_par_name = "lambda",
#               col_par_name = "theta",
#               cv_err_matr_name = "cv.err.matr",
#               row_par_min_name = "lmin",
#               col_par_min_name = "tmin",
#               my.main = "LASSO Negative Binomial  Cv error contour",
#               my.xlab = "log lambda",
#               my.ylab = "theta")

par(mfrow = c(1,1))
```

```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```


```{r, results='hide' ,eval = bool_execute_heavy_chunks, warning=FALSE}

# LASSO ---------------------
temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = log(df_2010_grouped$count) -log(12),
                  lambda = models_summary$lasso$lmin)

models_summary$lasso$beta = temp.fit$beta
models_summary$lasso$test_error = RMSEfun(df_2011_grouped$count, 
                                          exp(predict(temp.fit, newx = df_2011_grouped.matrix) + log(12)))

temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = log(df_2010_grouped$count) -log(12),
                  lambda = models_summary$lasso$l1se)

models_summary$lasso$beta1se = temp.fit$beta
models_summary$lasso$test_error1se = RMSEfun(df_2011_grouped$count, 
                                          exp(predict(temp.fit, newx = df_2011_grouped.matrix) + log(12)))

# Elasticnet ---------------------
temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = log(df_2010_grouped$count) -log(12),
                  alpha = models_summary$elasticnet$amin,
                  lambda = models_summary$elasticnet$lmin)

models_summary$elasticnet$beta = temp.fit$beta
models_summary$elasticnet$test_error = RMSEfun(df_2011_grouped$count, 
                                          exp(predict(temp.fit, newx = df_2011_grouped.matrix) + log(12)))


# SCAD ---------------------
temp.fit = picasso(X = df_2010_grouped.matrix,
                  Y = log(df_2010_grouped$count) -log(12),
                  gamma = models_summary$scad$gmin,
                  lambda = models_summary$scad$lmin,
                  method = "scad")

temp.lind = which(models_summary$scad$lambda == models_summary$scad$lmin)

models_summary$scad$beta = temp.fit$beta
models_summary$scad$test_error = RMSEfun(df_2011_grouped$count, 
                                          exp(my.predict.gaussian(temp.fit, newdata = df_2011_grouped.matrix,
                                                               lambda.idx = 1) +
                                                log(12)))

# MCP ----------------------
temp.fit = picasso(X = df_2010_grouped.matrix,
                  Y = log(df_2010_grouped$count) -log(12),
                  gamma = models_summary$mcp$gmin,
                  lambda = models_summary$mcp$lmin,
                  method = "mcp")

temp.lind = which(models_summary$mcp$lambda == models_summary$mcp$lmin)

models_summary$mcp$beta = temp.fit$beta
models_summary$mcp$test_error = RMSEfun(df_2011_grouped$count, 
                                          exp(my.predict.gaussian(temp.fit, newdata = df_2011_grouped.matrix,
                                                               lambda.idx = 1) +
                                                log(12)))


# LASSO Poisson ---------------------
temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = df_2010_grouped$count,
                  offset = rep(log(12), nrow(df_2010_grouped.matrix)),
                  lambda = models_summary$lasso.poi$lmin,
                  family = poisson())

models_summary$lasso.poi$beta = temp.fit$beta
models_summary$lasso.poi$test_error = RMSEfun(df_2011_grouped$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped.matrix)),
                                                  type = "response"))

temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = df_2010_grouped$count,
                  offset = rep(log(12), nrow(df_2010_grouped.matrix)),
                  lambda = models_summary$lasso.poi$l1se,
                  family = poisson())

models_summary$lasso.poi$beta1se = temp.fit$beta
models_summary$lasso.poi$test_error1se = RMSEfun(df_2011_grouped$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped.matrix),
                                                  type = "response")))


# Elasticnet Poisson ---------------------
temp.fit = glmnet(x = df_2010_grouped.matrix,
                  y = df_2010_grouped$count,
                  offset = rep(log(12), nrow(df_2010_grouped.matrix)),
                  alpha = models_summary$elasticnet.poi$amin,
                  lambda = models_summary$lasso.poi$lmin,
                  family = poisson())

models_summary$elasticnet.poi$beta = temp.fit$beta
models_summary$elasticnet.poi$test_error = RMSEfun(df_2011_grouped$count, 
                                          predict(temp.fit,
                                                  newx = df_2011_grouped.matrix,
                                                  newoffset = rep(log(12), nrow(df_2011_grouped.matrix),
                                                  type = "response")))

```

```{r}
# backup to save key model info
save(models_summary, file = file_save_name)
```


Benchè con la libreria impiegata non siano fornite informazione precise sulla regione delle stime si può comunque provare a valutare la stabilità graficamente.

```{r, fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d, warning=FALSE}

par(mfrow = c(1,2))

# SCAD ---------------------
temp.fit = picasso(X = df_2010_grouped.matrix,
                  Y = log(df_2010_grouped$count) -log(12),
                  gamma = models_summary$scad$gmin,
                  lambda = models_summary$scad$lambda,
                  method = "scad")

plot(log(temp.fit$lambda), t(temp.fit$beta),
             type = "l", main = "SCAD Regularization Path", 
    xlab = "Regularization Parameter", ylab = "Coefficient")
abline(v = log(models_summary$scad$lmin))

# MCP ----------------------
temp.fit = picasso(X = df_2010_grouped.matrix,
                  Y = log(df_2010_grouped$count) -log(12),
                  gamma = models_summary$mcp$gmin,
                  lambda = models_summary$mcp$lambda,
                  method = "mcp")

matplot(log(temp.fit$lambda), t(temp.fit$beta),
        type = "l", main = "MCP Regularization Path", 
    xlab = "Regularization Parameter", ylab = "Coefficient")
abline(v = log(models_summary$mcp$lmin))

par(mfrow = c(1,1))
```

```{r, results='hide'}
rm(temp.fit)
suppressMessages(gc())
```




### Modelli migliori

Si riportano gli errori di previsione sui dati del 2011 dei vari modelli migliori stimati sui dati completi 2010. 
```{r}
models.errors = data.frame(model = c("lasso",
                                     "lasso.1se",
                                     "elasticnet",
                                     "scad",
                                     "mcp",
                                     "poisson_lasso",
                                     "poisson_lasso1se",
                                     "poisson_elasticnet"),
                           test_error = c(models_summary$lasso$test_error,
                                          models_summary$lasso$test_error1se,
                                          models_summary$elasticnet$test_error,
                                          models_summary$scad$test_error,
                                          models_summary$mcp$test_error,
                                          models_summary$lasso.poi$test_error,
                                          models_summary$lasso.poi$test_error1se,
                                          models_summary$elasticnet.poi$test_error))

models.errors
```


I grafici dei coefficienti stimati confermano, per LASSO ed Elasticnet una non selezione delle variabili.
```{r,  fig.show='hold', out.width = OUT.WIDTH.1d, out.height= OUT.HEIGHT.1d}

par(mfrow = c(1,2))
plot(models_summary$lasso$beta, pch = 16,
     main = "LASSO & Elasticnet",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$lasso$beta),as.vector(models_summary$elasticnet$beta))))
points(models_summary$elasticnet$beta, col = "red")

legend("bottomright",
       legend = c("LASSO", "Elasticnet"),
       col = c(1,2),
       lty = 1,
       bty = "n")

plot(models_summary$lasso.poi$beta, pch = 16,
      main = "Poisson LASSO & Elasticnet",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$lasso.poi$beta), as.vector(models_summary$elasticnet.poi$beta))))
points(models_summary$elasticnet.poi$beta, col = "red")

legend("bottomright",
       legend = c("LASSO", "Elasticnet"),
       col = c(1,2),
       lty = 1,
       bty = "n")
```

```{r}
plot(models_summary$scad$beta, pch = 16,
      main = "SCAD & MCP beta estimates",
     xlab = "beta index", ylab = "beta",
     ylim = range(c(as.vector(models_summary$scad$beta), as.vector(models_summary$mcp$beta))))
points(models_summary$mcp$beta, col = "red")

legend("bottomright",
       legend = c("SCAD", "MCP"),
       col = c(1,2),
       lty = 1,
       bty = "n")
```










