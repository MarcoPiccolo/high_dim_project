% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ,
]{article}
\title{Arrests 2010 NTA: Analisi}
\author{}
\date{\vspace{-2.5em}}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Arrests 2010 NTA: Analisi},
  pdflang={italian},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{float}
\ifXeTeX
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{}
\else
  \usepackage[main=]{babel}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\fi
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{analisi-nta-2010---2011-interazione-tra-variabili}{%
\section{Analisi NTA 2010 - 2011 interazione tra variabili}\label{analisi-nta-2010---2011-interazione-tra-variabili}}

\hypertarget{descrizione}{%
\subsection{Descrizione}\label{descrizione}}

L'obbiettivo di questa sezione di analisi è verificare se esiste un sottoinsieme di variabili esplicative particolarmente correlate con il numero di arresti, sia marginalmente che considerando l'interazione con ciascuna zona spaziale (NTA).
Per vincoli computazionali si riduce l'insieme di stima al solo anno 2010: per quest'anno i dati del censo sono esatti e non si sono verificati eventi rari a differenza del 2020 (Covid); l'insieme di verifica scelto è l'anno 2011, in quanto è l'anno più vicino al 2010 (l'assunzione è che i due anni siano abbastanza simili per il fenomeno considerato).

\hypertarget{problematiche}{%
\subsubsection{Problematiche}\label{problematiche}}

Questi dati presentano diverse problematiche.

Le scelte fatte sono dovute a fattori computazionali, di tempo e al fatto che per permettere conteggi diversi da 1 è necessario considerare zone spaziali e intervalli temporali non eccessivamente ristretti.

Per quanto concerne gli intervalli temporali si è scelto di ignorare i possibili trend e considerare i singoli anni, per ciascun anno si sono utilizzati i mesi per la costruzione degli insiemi di convalida incrociata. Pur avendo a disposizione il giorno di ciascun arresto la selezione dei mesi è apparsa come un giusto compromesso per garantire che non tutti i conteggi fossero uguali a 1 che comunque è il conteggio minino e più frequente molto superiore a tutti gli altri conteggi:

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-6-1} 

}

\caption{Tabella di frequenza assoluta per il numero di arresti raggruppando i dati del 2010 per tutte le variabili ad eccezione dei mesi}\label{fig:unnamed-chunk-6}
\end{figure}

Questa ``sovradispersione'' di 1 è ragionevole data la costruzione dei conteggi per aggregazione di osservazioni con le stesse combinazioni di covariate; si dovrebbero inoltre aggiungere osservazioni con conteggi nulli per ogni combinazione di variabili per cui non si sono osservati arresti.

Mantenere tutti i conteggi unitari rende computazionalmente molto oneroso l'addattamenteo dei modelli e può creare problemi nella selezione degli stessi

La soluzione adottata è basata sul sottocampionamento: si stabilisce una soglia per i valori di conteggi oltre cui non sottocampionare, si conta la frequenza di conteggi osservati per tale soglia e si sottocampiona un sottoinsieme di grandezza uguale a quella frequenza da ciascun sottoinsieme di conteggi con valori inferiori alla soglia.

L'assunzione di fondo è che, almeno per i conteggi fino alla soglia considerata, la frequenza sia descrescente rispetto al valore degli stessi; un aspetto da sottolineare della metodologia proposta, in quanto compromesso, è che introduce distorsione nelle stime.

Si considerano due tipologie di dataset, entrambi impiegano il sottocampiomamento, ma in uno i conteggi nulli sono presenti e nell'altro sono assenti (i modelli per risposta continua sono adattati impiegando una trasformazione logaritmica dei dati senza conteggi nulli).

Per questo studio la soglia selezionata che è apparsa ragionevole in base alle considerazioni precedenti è di conteggi uguali a 10.

Il sottocampionamento è effettuato anche per i dataset completi relativi a 2010 e 2011 (escludendo i mesi come variabile di raggruppamento), ma non sono stati aggiunti gli zeri per permettere il confronto tra modelli per risposta continua.

\hypertarget{elevata-dimensionalituxe0}{%
\subsubsection{Elevata dimensionalità}\label{elevata-dimensionalituxe0}}

I dati presentano elevata dimensionalità considerando le interazioni tra la variabile spaziale (NTA) e le covariate (qualitative) di arrests.
E' comunque interessante provare i metodi di selezione delle variabili anche sui dati senza interazioni.

Per avere delle misure quantitative si considera il dataset in cui si sono definiti i conteggi senza considerare i mesi: si riporta il rapporto tra il numero di osservazioni (righe) e il prodotto tra il numero di modalità di NTA e la somma delle modalità delle variabili qualitative di arrests.

Senza considerare interazioni tra KY\_CD (esplicativa non spaziale di arrest con più modalità) con gli NTA il rapporto è (considerando i dati 2011 :

\begin{verbatim}
##  NTA2020 
## 3.816125
\end{verbatim}

Considerando anche interazioni tra KY\_CD e NTA rapporto è:

\begin{verbatim}
##   NTA2020 
## 0.9178023
\end{verbatim}

\hypertarget{modelli}{%
\subsection{Modelli}\label{modelli}}

\hypertarget{criterio-di-selezione-dei-parametri-di-regolazione}{%
\subsubsection{Criterio di selezione dei parametri di regolazione}\label{criterio-di-selezione-dei-parametri-di-regolazione}}

Come già accennato, i parametri di regolazione sono selezionati tramite convalida incrociata (CV) impiegando i mesi per la costruzione degli insiemi.

La procedura per la costruzione degli insiemi è la seguente:
- Selezione di k: il numero di insiemi di convalida (ad esempio k = 4)
- Ogni insieme di convalida è composto da osservazioni raggruppate di 12 / k (3) mesi e i mesi rimanenti (9) vengono utilizzati per adattare il modello.
- Per cercare di compensare e mediare le fluttuazioni stagionali, i mesi di validazione sono scelti il più distanziati possibile. Ad esempio, nel caso di k = 4, il primo insieme di validazione è (gennaio, maggio, settembre), il secondo set è (febbraio, giugno, ottobre), il terzo è (marzo, luglio, novembre) e il quarto è (aprile, agosto, dicembre).
- Per rendere ogni risposta comparabile avendo utilizzato un numero diverso di mesi, una nuova risposta è definita come il rapporto degli arresti diviso per il numero di mesi utilizzati nel raggruppamento (ovvero l'esponenziale dell 'offset nel modello di Poisson).

\hypertarget{matrice-del-modello}{%
\subsubsection{Matrice del modello}\label{matrice-del-modello}}

La matrice del modello considerata è quella con tutte le variabili e le interazioni tra tutte le variabili di arrests tranne KY\_CD (per ragioni computazionali) e le zone spaziali degli NTA.

Poichè la matrice del modello dell'insieme di verifica e quella dell'insieme di stima non condividono tutte le colonne si considerare solo le colonne in comune alle due.

\begin{verbatim}
## [1] 17039  4094
\end{verbatim}

\begin{verbatim}
## [1] 17164  4109
\end{verbatim}

\hypertarget{esplicative-quantitative}{%
\subsubsection{Esplicative quantitative}\label{esplicative-quantitative}}

IL dtaset presenta principalmente esplicative categoriali, benchè le due esplicative quantitative (MdAge) permettano la specificazione di diverse forme funzionali qui, per ragioni computazionali ci si limita ad assumere una relazione monotona lineare con la risposta.

\hypertarget{modelli-per-risposta-continua}{%
\subsubsection{Modelli per risposta continua}\label{modelli-per-risposta-continua}}

Nell'impiego dei modelli con risposta continua (con errori gaussiani i.i.d) si è scelto di stimare il modello su una trasformazione logaritmica della risposta: ``y = count / n\_month\_train'' (per i dati senza introduzione di conteggi nulli) e calcolare l'errore di previsioni sulla trasformazione ``count = exp(y) * n\_month\_test'' rispetto al numero di conteggi osservati, in questo modo la previsione è sempre positiva.

\hypertarget{modelli-e-procedure-considerati}{%
\subsubsection{Modelli e procedure considerati}\label{modelli-e-procedure-considerati}}

I modelli considerati sono modelli normali con penalizzazioni LASSO, Elasticnet, SCAD ed MCP e modelli Poisson con penalizzazioni LASSO ed Elasticnet. Per per tutti i modelli si seleziona il parametro (eventualmente vettoriale) di regolazione che minimizza l'errore di convalida. Per i metodi per cui il parametro di regolarizzazione ha dimensione 2 si definisce una griglia di valori (di cui si riporta il grafico delle curve di livello dell'errore).
Per i metodi SCAD e MCP, poichè ``ncvreg'' presenta dei problemi computazionali dovute alle dimensioni del dataset è impiegata la libreria ``picasso'' che però non fornisce indicazioni rispetto alle regioni non convesse.

Per il modello normale il \(\lambda\) minimo è molto vicino a zero (poichè la soluzione è sul bordo si dovrebbe provare a diminuire ulteriormente \(\lambda\), ma già così i coefficienti sono quasi uguali alle stime non penalizzate).
Per il modello Poisson il \(\lambda\) selezionato è maggiore. (Figura
\(\@ref(fig:cv_err_lasso_linear_poi)\))

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/cv_err_lasso_linear_poi-1} 

}

\caption{Grafici dell'errore di convalida incrociata in funzione del parametro di regolazione per LASSO per moodelli lineare e Poisson}(\#fig:cv_err_lasso_linear_poi)
\end{figure}

Per il modello continuo Elasticnet individua un \(\alpha\) intermedio tra Ridge e LASSO, ma come sopra il \(\lambda\) è prossimo a zero (considerazioni uguali a sopra), nel modello Poisson invece è selezionata una Ridge con \(\lambda\) non prossimo a zero.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-27-1} \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-27-2} 

}

\caption{Curve di livello dell'errore di convalida incrociata in funzione dei parametri di regolazione per Elasticnet dei modelli lineare e Poisson}\label{fig:unnamed-chunk-27}
\end{figure}

Sia per SCAD che per MCP il \(\lambda\) selezionato è prossimo a zero, provando ad aumentare ulteriormente \(\gamma\) e diminuire \(\lambda\) la soluzione sostanzialmente non cambia.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-28-1} \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-28-2} 

}

\caption{Curve di livello dell'errore di convalida incrociata in funzione dei parametri di regolazione per SCAD ed MCP del modello lineare}\label{fig:unnamed-chunk-28}
\end{figure}

Per i modelli di Poisson adattati con conteggi nulli i \(\lambda\) ottimi tendono al metodo non penalizzato; nel caso di Elasticnet è selezionata una ridge.

\begin{figure}

{\centering \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-29-1} \includegraphics[width=0.45\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-29-2} 

}

\caption{Grafici dell'errore di convalida incrociata in funzione dei parametri di regolazione per LASSO ed Elasticnet per modelli Poisson per dati con aggiunta di zeri}\label{fig:unnamed-chunk-29}
\end{figure}

Per confontare modelli per risposta continua e discreta nelle previsioni sui dati 2011 si approssimano le previsioni continue al primo intero

\begin{verbatim}
## Warning in rm(temp.fit): oggetto 'temp.fit' non trovato
\end{verbatim}

\hypertarget{modelli-migliori}{%
\subsubsection{Modelli migliori}\label{modelli-migliori}}

Si riportano gli errori di previsione sui dati del 2011 (senza zeri) dei vari modelli migliori stimati sui dati completi 2010 (senza zeri). La milgior previsione si ha per il modello Poisson con penalità LASSO (selezionato sui dati con gli zeri) per \(\lambda\) a errore a un errore standard, mentre il peggiore è sempre il modello di Poisson ma con penalità Elasticnet.

\begin{verbatim}
##                       model test_error
## 1                     lasso   21.27275
## 2                 lasso.1se   21.32034
## 3                elasticnet   21.27275
## 4                      scad   20.24735
## 5                       mcp   20.24735
## 6             poisson_lasso   17.07644
## 7          poisson_lasso1se   30.24875
## 8        poisson_elasticnet   30.25221
## 9       poisson_lasso.zeros   16.97896
## 10  poisson_lasso.zeros.1se   16.76682
## 11 poisson_elasticnet_zeros   30.24320
\end{verbatim}

I grafici dei coefficienti stimati confermano, per LASSO ed Elasticnet non avviene selezione delle variabili.
Le stime non sono sparse nemmeno con il criterio dell'errore a un errore standard.
Anche per SCAD ed MCP non avviene selezione di variabili: le stime (non riportate) sono quasi uguali a quelle LASSO ed Elasticnet.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-35-1} 

}

\caption{Grafici dei coefficienti stimati sui dati 2010 dei modelli selezionati precedentemente per LASSO ed Elasticnet per modelli lineare e Poisson}\label{fig:unnamed-chunk-35}
\end{figure}

I modelli Poisson adattati considerando gli zeri presentano una maggiore selezione di variabili rispetto ai precedenti.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-37-1} 

}

\caption{Grafici dei coefficienti stimati sui dati 2010 dei modelli Poisson (LASSO) selezionati precedentemente sui dati con aggiunta di zeri}\label{fig:unnamed-chunk-37}
\end{figure}

La tabella sottostante contiene per ciascun modello il rapporto tra il numero di elementi non nulli e il numero di elementi totali del vettore dei coefficienti: il modello Poisson con penalizzazione LASSO (criterio a un errore standard) e impiegando gli zeri è quello con il rapporto minore, questo modello è dunque l'oggetto delle successive analisi.

E' interessante notare come il modello con la migliore previsione sui dati 2011 sia quello con penalizzazione LASSO e non Elastic, come ci si sarebbe potuti invece aspettare data la natura di correlazione delle esplicative data dall'introduzione dei termini di interazione.
Poichè le stime LASSO per esplicative correlate non sono stabili le conclusioni inferenziali ed intepretative devono essere prese con cautela.

Si ricorda che per GLM di Poisson con legame canonico, in assenza di interazioni, l'aumento unitario di una variabile fissate tutte le altre induce una modifica moltiplicativa nel parametro della media pari all'esponenziale del coefficiente associato alla variabile. Nel caso considerato il parametro è il numero di arresti medi mensili (poichè si è introdotto l'offset). Sono presenti delle ulteriori difficoltà interpretative dei coefficienti dovuti alla standardizzazione delle variabili e al sottocampionamento che di fatto sottostima il numero di conteggi nulli o bassi. In questa analisi si è inoltre più interessati alle variabili associate a un incremento degli arresti più che a una loro diminuizione.

\begin{verbatim}
##                       model not_null_ratio
## 1                     lasso      0.7082824
## 2                 lasso.1se      0.5223552
## 3                elasticnet      0.7082824
## 4                      scad      0.7082824
## 5                       mcp      0.7082824
## 6             poisson_lasso      0.6017591
## 7          poisson_lasso1se      0.4348888
## 8        poisson_elasticnet      0.7082824
## 9       poisson_lasso.zeros      0.5668214
## 10  poisson_lasso.zeros.1se      0.4273149
## 11 poisson_elasticnet_zeros      0.7082824
\end{verbatim}

E' riportata la mappa degli NTA colorati in base al valore del corrispettivo coefficiente (marginale) (le zone grigie corrispondono a zone non presenti nei dati, e quindi coefficienti non stimati),per alcuni NTA sono presenti i nomi dei corrispettivi codici, questi sono in corrispondenza dei coefficienti più grandi relativi a termini di interazione in cui sono presenti tali NTA (vedasi sotto).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-41-1} 

}

\caption{Grafici dei coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri relativi a ciascun NTA}\label{fig:unnamed-chunk-41}
\end{figure}

Si riportano anche le tabelle dei cofficienti per le variabili qualitative (marginali).

Tutti i gruppi di età presentao coefficienti positivi ad eccezione della fascia più anziana.

\begin{verbatim}
##   AGE_GROUP       beta
## 1     18-24  0.5345937
## 2     25-44  0.7143626
## 3     45-64  0.1530545
## 4       65+ -1.5297436
\end{verbatim}

La percentuale di maschi è associata ad un coefficiente positivo.

\begin{verbatim}
##   PERP_SEX     beta
## 1        M 0.992226
\end{verbatim}

I coefficienti positivi sono relativi a razza bianca, ispanica e nera.

\begin{verbatim}
##                  PERP_RACE        beta
## 1 ASIAN / PACIFIC ISLANDER  0.00000000
## 2                    BLACK  1.23406301
## 3           BLACK HISPANIC  0.06751106
## 4                  UNKNOWN -0.65693016
## 5                    WHITE  0.87761786
## 6           WHITE HISPANIC  0.84684298
\end{verbatim}

I coefficienti relativi alle variabili del censo sono relativamente piccoli rispetto a quelli per le altre variabili.

\begin{verbatim}
##       var          beta
## 1    Pop1  1.015651e-06
## 2   MdAge  1.254768e-03
## 3   MaleP  0.000000e+00
## 4   Hsp1P  4.890527e-03
## 5    BNHP  0.000000e+00
## 6  OthNHP -7.457973e-02
## 7    WNHP -3.323548e-03
## 8    ANHP  1.069909e-02
## 9 MIncome  6.372898e-06
\end{verbatim}

Per le macro categorie di reato solo l'omicidio presenta una coefficiente positivo.

\begin{verbatim}
##   LAW_CAT_CD       beta
## 1          F -0.1766663
## 2          I -0.7154991
## 3          M  0.8270686
## 4          V -0.4761718
\end{verbatim}

Si riporta il grafico dei coefficienti per le categorie più granulari di arresto.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-48-1} 

}

\caption{Grafici dei coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri relativi alle categorie granulare di arresto KYCD}\label{fig:unnamed-chunk-48}
\end{figure}

Poichè si è più interessati ai termini correlati positivamente con il numero di arresti si riportano di seguito i 20 coefficienti più grandi del modello Poisson più sparso descritto sopra.

Il termine più grande e gli altri due che coinvolgono l'interazioe tra NTA e la fascia d'età massima compensano il valore negativo del coefficiente marginale per quella fascia d'età per quelle specifiche zone; un ragionamento analogo vale per i termini di interazione che comprendono la modalità ``razza asiatica''.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth,height=0.6\textheight]{arrests_2010_nta_files/figure-latex/unnamed-chunk-49-1} 

}

\caption{Grafici dei 20 più grandi coefficienti stimati sui dati 2010 del modello Poisson (LASSO) selezionato con criterio a un errore standard sui dati con aggiunta di zeri}\label{fig:unnamed-chunk-49}
\end{figure}

\end{document}
